# -*- coding: utf-8 -*-
"""summer work ff.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1macYkVGdhmtSX3bbhvU-FDbjt2Cnl3kS
"""

#导入库#
import torch
import torch.nn as nn
import torch.optim as optim
import torch.nn.functional as F
from torchvision import datasets
import torchvision.transforms as transforms
from torch.utils.data import sampler

to_float = torch.float
to_long = torch.long

if torch.cuda.is_available():
  device = torch.device('cuda')
else:
  device = torch.device('cpu')
print(device)

batch_size = 64

transform = transforms.Compose([
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.5], std=[0.5])#归一#
    ])

train_data = datasets.CIFAR10('data', train=True,
                              download=True, transform=transform)
test_data = datasets.CIFAR10('data', train=False,
                             download=True, transform=transform)

NUM_TRAIN = 49000
train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size,
    sampler=sampler.SubsetRandomSampler(range(NUM_TRAIN)))
valid_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, 
    sampler=sampler.SubsetRandomSampler(range(NUM_TRAIN, 50000)))
test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size)

class Net(nn.Module):
    def __init__(self):
        super().__init__()
        
        self.net = nn.Sequential(
            nn.Conv2d(3, 6, 5),
            nn.BatchNorm2d(6),
            nn.ReLU(),
            nn.MaxPool2d(2, 2),
            
            nn.Conv2d(6, 16, 5),
            nn.BatchNorm2d(16),
            nn.ReLU(),
            nn.MaxPool2d(2, 2),
            
            nn.Conv2d(16, 32, 3),
            nn.ReLU(),
            nn.MaxPool2d(2, 2),
            
            nn.Flatten(),
            nn.Linear(1*1*32, 16),
            nn.ReLU(),
            
            nn.Linear(16, 6),
        )
        
    def forward(self, x):
        return self.net(x)
model = Net()
print(model)
optimizer = optim.SGD(model.parameters(), lr=0.01)

def check_accuracy_part34(loader, model):
  num_correct = 0
  num_samples = 0
  model.eval()  
  with torch.no_grad():
    for x, y in loader:
      x = x.to(device=device, dtype=to_float) 
      y = y.to(device=device, dtype=to_long).clamp(max=5)
      scores = model(x)
      _, preds = scores.max(1)
      num_correct += (preds == y).sum()
      num_samples += preds.size(0)
    acc = float(num_correct) / num_samples
    print('Got %d / %d correct (%.2f)' % (num_correct, num_samples, 100 * acc))
  return acc

epochs = 5
num_prints = epochs * len(train_loader) // 100 + 1
acc_history = torch.zeros(num_prints, dtype=to_float)
iter_history = torch.zeros(num_prints, dtype=to_long)
model = model.to(device=device)
for epoch in range(epochs):
    for t, (x, y) in enumerate(train_loader):
        model.train()
        x = x.to(device=device, dtype=to_float)
        y = y.to(device=device, dtype=to_long).clamp(max=5)
        
        scores = model(x)
        loss = F.cross_entropy(scores, y)
        
        optimizer.zero_grad()
        
        loss.backward()
        
        optimizer.step()
        
        tt = t + epoch * len(train_loader)
        
        if tt % 100 == 0 or (epoch == epochs - 1 and t == len(train_loader) - 1):
            print("Epoch: %d, Iteration: %d, loss = %.4f" %(epoch, tt, loss.item()))
            acc = check_accuracy_part34(valid_loader, model)
            acc_history[tt // 100] = acc
            iter_history[tt // 100] = tt
            print()

import matplotlib.pyplot as plt
plt.title('Val accuracies')
plt.plot(iter_history, acc_history, '-o')
plt.xlabel('iterations')
plt.ylabel('accuracy')
plt.show()

import matplotlib.pyplot as plt
import numpy as np

data_loader = torch.utils.data.DataLoader(test_data, batch_size=1, shuffle=True)
image, label = next(iter(data_loader))
image = image.to(device=device, dtype=to_float)
label = label.to(device=device, dtype=to_long).clamp(max=5)
scores = model(image)
_, pred = scores.max(1)
print('Predict label is: ', pred)
#to_pil_image = transforms.ToPILImage()
#img = to_pil_image(image[0])
img = image[0].cpu().numpy().transpose(1,2,0)
mean = [0.5]
std = [0.5]
img = img * std + mean
#plt.figure(figsize=(1, 1))
plt.imshow(img)
print('Real lable is: ', label)

#x_test = x_test.to(device=device, dtype=to_float)
#y_test =