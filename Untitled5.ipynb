{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled5.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyO9/rpRle7USywU9So8HORm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/budaoweng98/-/blob/main/Untitled5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OZEkoWiqEQ_t"
      },
      "source": [
        "# **导入库**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B_4x-j9gEIWS",
        "outputId": "fae4e182-4bd3-4d99-8174-012ac63ea98f"
      },
      "source": [
        "#导入库#\n",
        "import os\n",
        "import shutil\n",
        "import random\n",
        "from PIL import Image\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torchvision import datasets\n",
        "import torchvision.transforms as transforms\n",
        "#from torch.utils.data.sampler import SubsetRandomSampler\n",
        "from torch.utils.data import sampler\n",
        "\n",
        "to_float = torch.float\n",
        "to_long = torch.long\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "  device = torch.device('cuda')\n",
        "else:\n",
        "  device = torch.device('cpu')\n",
        "print(device)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OXB8n_gVFEC1"
      },
      "source": [
        "# **解压文件**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4oir3ptbJwMr"
      },
      "source": [
        "import zipfile\n",
        "file_dir = '/cifar-10.zip' \n",
        "zipFile = zipfile.ZipFile(file_dir)\n",
        "for file in zipFile.namelist():\n",
        "    zipFile.extract(file, '/content')  \n",
        "zipFile.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mJ4jWHKsFKTb"
      },
      "source": [
        "# **导入数据**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LG9Xjv9NLkLa"
      },
      "source": [
        "train_data = datasets.ImageFolder('/content/train')\n",
        "test_data = datasets.ImageFolder('/content/test')"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zXfWfqyGFPpP"
      },
      "source": [
        "# **检查准确函数**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "glisCREeL6do"
      },
      "source": [
        "#检查准确函数\n",
        "def check_accuracy_part34(loader, model):\n",
        "  #if loader.dataset.train:\n",
        "  #  print('Checking accuracy on validation set')\n",
        "  #else:\n",
        "  #  print('Checking accuracy on test set')   \n",
        "  num_correct = 0\n",
        "  num_samples = 0\n",
        "  model.eval()  # set model to evaluation mode\n",
        "  with torch.no_grad():\n",
        "    for x, y in loader:\n",
        "      x = x.to(device=device, dtype=to_float)  # move to device, e.g. GPU\n",
        "      y = y.to(device=device, dtype=to_long).clamp(max=5)\n",
        "      scores = model(x)\n",
        "      _, preds = scores.max(1)\n",
        "      num_correct += (preds == y).sum()\n",
        "      num_samples += preds.size(0)\n",
        "    acc = float(num_correct) / num_samples\n",
        "    print('Got %d / %d correct (%.2f)' % (num_correct, num_samples, 100 * acc))\n",
        "  return acc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2DW6pVHoFUjp"
      },
      "source": [
        "# **验证集观测**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "6A_aAyacMFV1",
        "outputId": "ec63dd52-804a-4896-97ab-924c1c524b4c"
      },
      "source": [
        "#验证集观测\n",
        "main_dir = os.getcwd()\n",
        "train_dir = main_dir + \"/extract_train\"\n",
        "test_dir = main_dir + \"/extract_test\"\n",
        "\n",
        "epochs = 1\n",
        "total = []\n",
        "\n",
        "for i in range(5):\n",
        "    #建立存放数据集的文件夹\n",
        "    if os.path.exists(train_dir) and os.path.exists(test_dir):\n",
        "        shutil.rmtree(train_dir)\n",
        "        shutil.rmtree(test_dir)\n",
        "        os.mkdir(train_dir)\n",
        "        os.mkdir(test_dir)\n",
        "    else:\n",
        "        os.mkdir(train_dir)\n",
        "        os.mkdir(test_dir)\n",
        "        \n",
        "    #生成6个随机数，用于提取数据集中的6类\n",
        "    class_6 = torch.randperm(10)[:6]\n",
        "    print(\"Extract classes: \", class_6, \"\\n\")\n",
        "\n",
        "    #提取6类并保存至新的文件夹\n",
        "    for i in range(50000):\n",
        "        train_label = train_data.imgs[i][1]\n",
        "\n",
        "        if train_label in class_6:\n",
        "            train_label_dir = train_dir + \"/\" + str(train_label)\n",
        "            if os.path.exists(train_label_dir):\n",
        "                pass\n",
        "            else:\n",
        "                os.mkdir(train_label_dir)\n",
        "            image_path = train_data.imgs[i][0]\n",
        "            image = Image.open(image_path)\n",
        "            save_path = train_label_dir + \"/\" + str(i) + \".jpg\"\n",
        "            image.save(save_path)\n",
        "\n",
        "    for i in range(10000):\n",
        "        test_label = test_data.imgs[i][1]\n",
        "\n",
        "        if test_label in class_6:\n",
        "            test_label_dir = test_dir + \"/\" + str(test_label)\n",
        "            if os.path.exists(test_label_dir):\n",
        "                pass\n",
        "            else:\n",
        "                os.mkdir(test_label_dir)\n",
        "            image_path = test_data.imgs[i][0]\n",
        "            image = Image.open(image_path)\n",
        "            save_path = test_label_dir + \"/\" + str(i) + \".jpg\"\n",
        "            image.save(save_path)\n",
        "            \n",
        "    #定义预处理操作\n",
        "    Transforms = transforms.Compose([\n",
        "      transforms.Resize((224, 224)),\n",
        "      transforms.RandomHorizontalFlip(p=0.5),\n",
        "      transforms.ToTensor(),\n",
        "      transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))])\n",
        "\n",
        "    #数据集预处理\n",
        "    train_data_ = datasets.ImageFolder(train_dir, transform=transform)\n",
        "    test_data_ = datasets.ImageFolder(test_dir, transform=transform)\n",
        "\n",
        "    #数据集采样、打包\n",
        "    n_train = len(train_data_)  #30000\n",
        "\n",
        "    split = 23250\n",
        "    indices = list(range(n_train))\n",
        "    random.shuffle(indices)\n",
        "\n",
        "    train_loader = torch.utils.data.DataLoader(train_data_, batch_size=64, \n",
        "                                              sampler=sampler.SubsetRandomSampler(indices[:split]))\n",
        "    valid_loader = torch.utils.data.DataLoader(train_data_, batch_size=64, \n",
        "                                            sampler=sampler.SubsetRandomSampler(indices[split:]))\n",
        "    test_loader = torch.utils.data.DataLoader(test_data_, batch_size=64, shuffle=True)\n",
        "    \n",
        "    #定义网络与参数更新方法\n",
        "    model = Net()\n",
        "    optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
        "    \n",
        "    #训练网络\n",
        "    num_prints = epochs * len(train_loader) // 100 + 1\n",
        "    acc_history = torch.zeros(num_prints, dtype=to_float)\n",
        "    iter_history = torch.zeros(num_prints, dtype=to_long)\n",
        "    model = model.to(device=device)# move the model parameters to CPU/GPU\n",
        "    for epoch in range(epochs):\n",
        "        for t, (x, y) in enumerate(train_loader):\n",
        "            model.train()\n",
        "            # Move the data to the proper device (GPU or CPU)\n",
        "            x = x.to(device=device, dtype=to_float)\n",
        "            y = y.to(device=device, dtype=to_long).clamp(max=5)\n",
        "\n",
        "            # Forward pass: compute scores and loss\n",
        "            scores = model(x)\n",
        "            loss = F.cross_entropy(scores, y)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            #Backwards pass: compute the gradient\n",
        "            loss.backward()\n",
        "\n",
        "            #Update the parameters\n",
        "            optimizer.step()\n",
        "\n",
        "            tt = t + epoch * len(train_loader)\n",
        "\n",
        "            if tt % 100 == 0 or (epoch == epochs - 1 and t == len(train_loader) - 1):\n",
        "                print(\"Epoch: %d, Iteration: %d, loss = %.4f\" %(epoch, tt, loss.item()))\n",
        "                acc = check_accuracy_part34(valid_loader, model)\n",
        "                acc_history[tt // 100] = acc\n",
        "                iter_history[tt // 100] = tt\n",
        "                print()\n",
        "    total.append(acc_history[-1])\n",
        "    \n",
        "final_acc = sum(total) / len(total) * 100\n",
        "print(\"Final accuracy: %.2f\" %final_acc)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extract classes:  tensor([8, 1, 6, 4, 0, 2]) \n",
            "\n",
            "Epoch: 0, Iteration: 0, loss = 1.8016\n",
            "Got 1124 / 6750 correct (16.65)\n",
            "\n",
            "Epoch: 0, Iteration: 100, loss = 1.7890\n",
            "Got 1384 / 6750 correct (20.50)\n",
            "\n",
            "Epoch: 0, Iteration: 200, loss = 1.7772\n",
            "Got 1738 / 6750 correct (25.75)\n",
            "\n",
            "Epoch: 0, Iteration: 300, loss = 1.6397\n",
            "Got 1970 / 6750 correct (29.19)\n",
            "\n",
            "Epoch: 0, Iteration: 363, loss = 1.5852\n",
            "Got 2097 / 6750 correct (31.07)\n",
            "\n",
            "Extract classes:  tensor([3, 0, 8, 2, 1, 4]) \n",
            "\n",
            "Epoch: 0, Iteration: 0, loss = 1.8146\n",
            "Got 1104 / 6750 correct (16.36)\n",
            "\n",
            "Epoch: 0, Iteration: 100, loss = 1.7535\n",
            "Got 1854 / 6750 correct (27.47)\n",
            "\n",
            "Epoch: 0, Iteration: 200, loss = 1.6876\n",
            "Got 2102 / 6750 correct (31.14)\n",
            "\n",
            "Epoch: 0, Iteration: 300, loss = 1.5497\n",
            "Got 2078 / 6750 correct (30.79)\n",
            "\n",
            "Epoch: 0, Iteration: 363, loss = 1.5109\n",
            "Got 2310 / 6750 correct (34.22)\n",
            "\n",
            "Extract classes:  tensor([5, 0, 6, 9, 8, 3]) \n",
            "\n",
            "Epoch: 0, Iteration: 0, loss = 1.8422\n",
            "Got 1101 / 6750 correct (16.31)\n",
            "\n",
            "Epoch: 0, Iteration: 100, loss = 1.7466\n",
            "Got 2036 / 6750 correct (30.16)\n",
            "\n",
            "Epoch: 0, Iteration: 200, loss = 1.6437\n",
            "Got 1994 / 6750 correct (29.54)\n",
            "\n",
            "Epoch: 0, Iteration: 300, loss = 1.4765\n",
            "Got 2178 / 6750 correct (32.27)\n",
            "\n",
            "Epoch: 0, Iteration: 363, loss = 1.3212\n",
            "Got 2228 / 6750 correct (33.01)\n",
            "\n",
            "Extract classes:  tensor([9, 0, 1, 3, 6, 2]) \n",
            "\n",
            "Epoch: 0, Iteration: 0, loss = 1.8277\n",
            "Got 1145 / 6750 correct (16.96)\n",
            "\n",
            "Epoch: 0, Iteration: 100, loss = 1.7853\n",
            "Got 1205 / 6750 correct (17.85)\n",
            "\n",
            "Epoch: 0, Iteration: 200, loss = 1.7282\n",
            "Got 1964 / 6750 correct (29.10)\n",
            "\n",
            "Epoch: 0, Iteration: 300, loss = 1.6201\n",
            "Got 2195 / 6750 correct (32.52)\n",
            "\n",
            "Epoch: 0, Iteration: 363, loss = 1.4418\n",
            "Got 2266 / 6750 correct (33.57)\n",
            "\n",
            "Extract classes:  tensor([0, 7, 2, 1, 9, 4]) \n",
            "\n",
            "Epoch: 0, Iteration: 0, loss = 1.8057\n",
            "Got 1151 / 6750 correct (17.05)\n",
            "\n",
            "Epoch: 0, Iteration: 100, loss = 1.7688\n",
            "Got 1450 / 6750 correct (21.48)\n",
            "\n",
            "Epoch: 0, Iteration: 200, loss = 1.7541\n",
            "Got 1703 / 6750 correct (25.23)\n",
            "\n",
            "Epoch: 0, Iteration: 300, loss = 1.6592\n",
            "Got 2076 / 6750 correct (30.76)\n",
            "\n",
            "Epoch: 0, Iteration: 363, loss = 1.6233\n",
            "Got 2041 / 6750 correct (30.24)\n",
            "\n",
            "Final accuracy: 32.42\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uL5oib-oFa0G"
      },
      "source": [
        "# **搭建卷积网络**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wA9JKbUeKhqj",
        "outputId": "39c97558-2ef7-4ecf-e1ef-af3d6f638e96"
      },
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.net = nn.Sequential(\n",
        "            nn.Conv2d(3, 6, 5),\n",
        "            nn.BatchNorm2d(6),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2, 2),\n",
        "            \n",
        "            nn.Conv2d(6, 16, 5),\n",
        "            nn.BatchNorm2d(16),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2, 2),\n",
        "            \n",
        "            nn.Conv2d(16, 32, 3),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2, 2),\n",
        "            \n",
        "            nn.Flatten(),\n",
        "            nn.Linear(1*1*32, 16),\n",
        "            nn.ReLU(),\n",
        "            \n",
        "            nn.Linear(16, 6),\n",
        "        )\n",
        "        \n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "model = Net()\n",
        "print(model)\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Net(\n",
            "  (net): Sequential(\n",
            "    (0): Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1))\n",
            "    (1): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU()\n",
            "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (4): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
            "    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (6): ReLU()\n",
            "    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (8): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1))\n",
            "    (9): ReLU()\n",
            "    (10): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (11): Flatten(start_dim=1, end_dim=-1)\n",
            "    (12): Linear(in_features=32, out_features=16, bias=True)\n",
            "    (13): ReLU()\n",
            "    (14): Linear(in_features=16, out_features=6, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TQrtxv9SFhN-"
      },
      "source": [
        "# **训练函数**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8U3dQsk3MQnD",
        "outputId": "c9a5743f-7ce9-438c-ca49-f1d19c02bc02"
      },
      "source": [
        "#训练\n",
        "model = Net()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
        "\n",
        "epochs = 5\n",
        "num_prints = epochs * len(train_loader) // 100 + 1\n",
        "acc_history = torch.zeros(num_prints, dtype=to_float)\n",
        "iter_history = torch.zeros(num_prints, dtype=to_long)\n",
        "model = model.to(device=device)# move the model parameters to CPU/GPU\n",
        "for epoch in range(epochs):\n",
        "    for t, (x, y) in enumerate(train_loader):\n",
        "        model.train()\n",
        "        # Move the data to the proper device (GPU or CPU)\n",
        "        x = x.to(device=device, dtype=to_float)\n",
        "        y = y.to(device=device, dtype=to_long).clamp(max=5)\n",
        "        \n",
        "        # Forward pass: compute scores and loss\n",
        "        scores = model(x)\n",
        "        loss = F.cross_entropy(scores, y)\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        #Backwards pass: compute the gradient\n",
        "        loss.backward()\n",
        "        \n",
        "        #Update the parameters\n",
        "        optimizer.step()\n",
        "        \n",
        "        tt = t + epoch * len(train_loader)\n",
        "        \n",
        "        if tt % 100 == 0 or (epoch == epochs - 1 and t == len(train_loader) - 1):\n",
        "            print(\"Epoch: %d, Iteration: %d, loss = %.4f\" %(epoch, tt, loss.item()))\n",
        "            acc = check_accuracy_part34(train_loader, model)\n",
        "            acc_history[tt // 100] = acc\n",
        "            iter_history[tt // 100] = tt\n",
        "            print()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 0, Iteration: 0, loss = 1.8903\n",
            "Got 3948 / 23250 correct (16.98)\n",
            "\n",
            "Epoch: 0, Iteration: 100, loss = 1.7640\n",
            "Got 7183 / 23250 correct (30.89)\n",
            "\n",
            "Epoch: 0, Iteration: 200, loss = 1.5943\n",
            "Got 8658 / 23250 correct (37.24)\n",
            "\n",
            "Epoch: 0, Iteration: 300, loss = 1.5355\n",
            "Got 9041 / 23250 correct (38.89)\n",
            "\n",
            "Epoch: 1, Iteration: 400, loss = 1.3422\n",
            "Got 9460 / 23250 correct (40.69)\n",
            "\n",
            "Epoch: 1, Iteration: 500, loss = 1.3950\n",
            "Got 10325 / 23250 correct (44.41)\n",
            "\n",
            "Epoch: 1, Iteration: 600, loss = 1.4268\n",
            "Got 10661 / 23250 correct (45.85)\n",
            "\n",
            "Epoch: 1, Iteration: 700, loss = 1.2113\n",
            "Got 10992 / 23250 correct (47.28)\n",
            "\n",
            "Epoch: 2, Iteration: 800, loss = 1.1046\n",
            "Got 11350 / 23250 correct (48.82)\n",
            "\n",
            "Epoch: 2, Iteration: 900, loss = 1.1134\n",
            "Got 11573 / 23250 correct (49.78)\n",
            "\n",
            "Epoch: 2, Iteration: 1000, loss = 1.1248\n",
            "Got 12186 / 23250 correct (52.41)\n",
            "\n",
            "Epoch: 3, Iteration: 1100, loss = 1.0543\n",
            "Got 12594 / 23250 correct (54.17)\n",
            "\n",
            "Epoch: 3, Iteration: 1200, loss = 1.0603\n",
            "Got 13013 / 23250 correct (55.97)\n",
            "\n",
            "Epoch: 3, Iteration: 1300, loss = 0.9633\n",
            "Got 13247 / 23250 correct (56.98)\n",
            "\n",
            "Epoch: 3, Iteration: 1400, loss = 1.1689\n",
            "Got 13496 / 23250 correct (58.05)\n",
            "\n",
            "Epoch: 4, Iteration: 1500, loss = 0.9340\n",
            "Got 13162 / 23250 correct (56.61)\n",
            "\n",
            "Epoch: 4, Iteration: 1600, loss = 1.2616\n",
            "Got 13548 / 23250 correct (58.27)\n",
            "\n",
            "Epoch: 4, Iteration: 1700, loss = 0.9644\n",
            "Got 14091 / 23250 correct (60.61)\n",
            "\n",
            "Epoch: 4, Iteration: 1800, loss = 1.0034\n",
            "Got 14366 / 23250 correct (61.79)\n",
            "\n",
            "Epoch: 4, Iteration: 1819, loss = 0.8448\n",
            "Got 13175 / 23250 correct (56.67)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VWvdgoYKFkt6"
      },
      "source": [
        "# **准确率**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pWSbD6PC9DYl",
        "outputId": "7a939ab5-7ba4-48f7-e6a1-8e118e19ec39"
      },
      "source": [
        "main_dir = os.getcwd()\n",
        "train_dir = main_dir + \"/extract_train\"\n",
        "test_dir = main_dir + \"/extract_test\"\n",
        "\n",
        "epochs = 1\n",
        "total = []\n",
        "\n",
        "for i in range(5):\n",
        "    #建立存放数据集的文件夹\n",
        "    if os.path.exists(train_dir) and os.path.exists(test_dir):\n",
        "        shutil.rmtree(train_dir)\n",
        "        shutil.rmtree(test_dir)\n",
        "        os.mkdir(train_dir)\n",
        "        os.mkdir(test_dir)\n",
        "    else:\n",
        "        os.mkdir(train_dir)\n",
        "        os.mkdir(test_dir)\n",
        "        \n",
        "    #生成6个随机数，用于提取数据集中的6类\n",
        "    class_6 = torch.randperm(10)[:6]\n",
        "    print(\"Extract classes: \", class_6, \"\\n\")\n",
        "\n",
        "    #提取6类并保存至新的文件夹\n",
        "    for i in range(50000):\n",
        "        train_label = train_data.imgs[i][1]\n",
        "\n",
        "        if train_label in class_6:\n",
        "            train_label_dir = train_dir + \"/\" + str(train_label)\n",
        "            if os.path.exists(train_label_dir):\n",
        "                pass\n",
        "            else:\n",
        "                os.mkdir(train_label_dir)\n",
        "            image_path = train_data.imgs[i][0]\n",
        "            image = Image.open(image_path)\n",
        "            save_path = train_label_dir + \"/\" + str(i) + \".jpg\"\n",
        "            image.save(save_path)\n",
        "\n",
        "    for i in range(10000):\n",
        "        test_label = test_data.imgs[i][1]\n",
        "\n",
        "        if test_label in class_6:\n",
        "            test_label_dir = test_dir + \"/\" + str(test_label)\n",
        "            if os.path.exists(test_label_dir):\n",
        "                pass\n",
        "            else:\n",
        "                os.mkdir(test_label_dir)\n",
        "            image_path = test_data.imgs[i][0]\n",
        "            image = Image.open(image_path)\n",
        "            save_path = test_label_dir + \"/\" + str(i) + \".jpg\"\n",
        "            image.save(save_path)\n",
        "              #定义预处理操作\n",
        "    Transforms = transforms.Compose([\n",
        "      transforms.Resize((224, 224)),\n",
        "      transforms.RandomHorizontalFlip(p=0.5),\n",
        "      transforms.ToTensor(),\n",
        "      transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))])\n",
        "\n",
        "\n",
        "    #数据集预处理\n",
        "    train_data_ = datasets.ImageFolder(train_dir, transform=transform)\n",
        "    test_data_ = datasets.ImageFolder(test_dir, transform=transform)\n",
        "\n",
        "    #数据集采样、打包\n",
        "    n_train = len(train_data_)  #30000\n",
        "\n",
        "    split = 21000\n",
        "    indices = list(range(n_train))\n",
        "    random.shuffle(indices)\n",
        "\n",
        "    train_loader = torch.utils.data.DataLoader(train_data_, batch_size=64, \n",
        "                                              sampler=sampler.SubsetRandomSampler(indices[:split]))\n",
        "    valid_loader = torch.utils.data.DataLoader(train_data_, batch_size=64, \n",
        "                                            sampler=sampler.SubsetRandomSampler(indices[split:]))\n",
        "    test_loader = torch.utils.data.DataLoader(test_data_, batch_size=64, shuffle=True)\n",
        "num_prints=epochs*len(test_loader)//100+1\n",
        "acc_history=torch.zeros(num_prints, dtype=to_float)\n",
        "iter_history=torch.zeros(num_prints, dtype=to_long)\n",
        "model=model.to(device=device)  # move the model parameters to CPU/GPU\n",
        "for epoch in range(epochs):\n",
        "   for t, (x, y) in enumerate(test_loader):\n",
        "            model.eval()\n",
        "            # Move the data to the proper device (GPU or CPU)\n",
        "            x=x.to(device=device, dtype=to_float)\n",
        "            y=y.to(device=device, dtype=to_long).clamp(max=5)\n",
        "            tt=t+epoch*len(test_loader)\n",
        "\n",
        "            if tt%100==0 or (epoch==epochs-1 and t==len(test_loader)-1):\n",
        "                print(\"Epoch: %d, Iteration: %d, loss = %.4f\"%(epoch, tt, loss.item()))\n",
        "                acc=check_accuracy_part34(test_loader, model)\n",
        "                acc_history[tt//100]=acc\n",
        "                iter_history[tt//100]=tt\n",
        "                print()\n",
        "total.append(acc_history[-1])\n",
        "\n",
        "final_acc=sum(total)/len(total)*100\n",
        "print(\"Final accuracy: %.2f\"%final_acc)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extract classes:  tensor([8, 0, 7, 4, 3, 1]) \n",
            "\n",
            "Extract classes:  tensor([1, 0, 7, 9, 5, 4]) \n",
            "\n",
            "Extract classes:  tensor([6, 8, 7, 1, 4, 3]) \n",
            "\n",
            "Extract classes:  tensor([2, 0, 1, 8, 4, 7]) \n",
            "\n",
            "Extract classes:  tensor([5, 1, 3, 2, 0, 6]) \n",
            "\n",
            "Epoch: 0, Iteration: 0, loss = 0.8448\n",
            "Got 1058 / 6000 correct (17.63)\n",
            "\n",
            "Epoch: 0, Iteration: 93, loss = 0.8448\n",
            "Got 1058 / 6000 correct (17.63)\n",
            "\n",
            "Final accuracy: 17.63\n"
          ]
        }
      ]
    }
  ]
}