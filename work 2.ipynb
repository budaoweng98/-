{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled5.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPzttDEPKrb+P1qZmsh0c6k",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/budaoweng98/-/blob/main/work%202.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B_4x-j9gEIWS",
        "outputId": "6434c1de-f4f9-46db-99f9-c965e9229afc"
      },
      "source": [
        "#导入库#\n",
        "import os\n",
        "import shutil\n",
        "import random\n",
        "from PIL import Image\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torchvision import datasets\n",
        "import torchvision.transforms as transforms\n",
        "#from torch.utils.data.sampler import SubsetRandomSampler\n",
        "from torch.utils.data import sampler\n",
        "\n",
        "to_float = torch.float\n",
        "to_long = torch.long\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "  device = torch.device('cuda')\n",
        "else:\n",
        "  device = torch.device('cpu')\n",
        "print(device)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4oir3ptbJwMr"
      },
      "source": [
        "import zipfile\n",
        "file_dir = '/cifar-10.zip'  # 你的压缩包路径\n",
        "zipFile = zipfile.ZipFile(file_dir)\n",
        "for file in zipFile.namelist():\n",
        "    zipFile.extract(file, '/content')  # 解压路径\n",
        "zipFile.close()"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LG9Xjv9NLkLa"
      },
      "source": [
        "train_data = datasets.ImageFolder('/content/train')\n",
        "test_data = datasets.ImageFolder('/content/test')"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "glisCREeL6do"
      },
      "source": [
        "def check_accuracy_part34(loader, model):\n",
        "  #if loader.dataset.train:\n",
        "  #  print('Checking accuracy on validation set')\n",
        "  #else:\n",
        "  #  print('Checking accuracy on test set')   \n",
        "  num_correct = 0\n",
        "  num_samples = 0\n",
        "  model.eval()  # set model to evaluation mode\n",
        "  with torch.no_grad():\n",
        "    for x, y in loader:\n",
        "      x = x.to(device=device, dtype=to_float)  # move to device, e.g. GPU\n",
        "      y = y.to(device=device, dtype=to_long).clamp(max=5)\n",
        "      scores = model(x)\n",
        "      _, preds = scores.max(1)\n",
        "      num_correct += (preds == y).sum()\n",
        "      num_samples += preds.size(0)\n",
        "    acc = float(num_correct) / num_samples\n",
        "    print('Got %d / %d correct (%.2f)' % (num_correct, num_samples, 100 * acc))\n",
        "  return acc"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6A_aAyacMFV1",
        "outputId": "af44ef58-cb01-4058-b62e-67722ff59db9"
      },
      "source": [
        "main_dir = os.getcwd()\n",
        "train_dir = main_dir + \"/extract_train\"\n",
        "test_dir = main_dir + \"/extract_test\"\n",
        "\n",
        "epochs = 1\n",
        "total = []\n",
        "\n",
        "for i in range(1):\n",
        "    #建立存放数据集的文件夹\n",
        "    if os.path.exists(train_dir) and os.path.exists(test_dir):\n",
        "        shutil.rmtree(train_dir)\n",
        "        shutil.rmtree(test_dir)\n",
        "        os.mkdir(train_dir)\n",
        "        os.mkdir(test_dir)\n",
        "    else:\n",
        "        os.mkdir(train_dir)\n",
        "        os.mkdir(test_dir)\n",
        "        \n",
        "    #生成6个随机数，用于提取数据集中的6类\n",
        "    class_6 = torch.randperm(10)[:6]\n",
        "    print(\"Extract classes: \", class_6, \"\\n\")\n",
        "\n",
        "    #提取6类并保存至新的文件夹\n",
        "    for i in range(50000):\n",
        "        train_label = train_data.imgs[i][1]\n",
        "\n",
        "        if train_label in class_6:\n",
        "            train_label_dir = train_dir + \"/\" + str(train_label)\n",
        "            if os.path.exists(train_label_dir):\n",
        "                pass\n",
        "            else:\n",
        "                os.mkdir(train_label_dir)\n",
        "            image_path = train_data.imgs[i][0]\n",
        "            image = Image.open(image_path)\n",
        "            save_path = train_label_dir + \"/\" + str(i) + \".jpg\"\n",
        "            image.save(save_path)\n",
        "\n",
        "    for i in range(10000):\n",
        "        test_label = test_data.imgs[i][1]\n",
        "\n",
        "        if test_label in class_6:\n",
        "            test_label_dir = test_dir + \"/\" + str(test_label)\n",
        "            if os.path.exists(test_label_dir):\n",
        "                pass\n",
        "            else:\n",
        "                os.mkdir(test_label_dir)\n",
        "            image_path = test_data.imgs[i][0]\n",
        "            image = Image.open(image_path)\n",
        "            save_path = test_label_dir + \"/\" + str(i) + \".jpg\"\n",
        "            image.save(save_path)\n",
        "            \n",
        "    #定义预处理操作\n",
        "    transform = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.5], std=[0.5])\n",
        "        ])\n",
        "\n",
        "    #数据集预处理\n",
        "    train_data_ = datasets.ImageFolder(train_dir, transform=transform)\n",
        "    test_data_ = datasets.ImageFolder(test_dir, transform=transform)\n",
        "\n",
        "    #数据集采样、打包\n",
        "    n_train = len(train_data_)  #30000\n",
        "\n",
        "    split = 23250\n",
        "    indices = list(range(n_train))\n",
        "    random.shuffle(indices)\n",
        "\n",
        "    train_loader = torch.utils.data.DataLoader(train_data_, batch_size=64, \n",
        "                                              sampler=sampler.SubsetRandomSampler(indices[:split]))\n",
        "    valid_loader = torch.utils.data.DataLoader(train_data_, batch_size=64, \n",
        "                                            sampler=sampler.SubsetRandomSampler(indices[split:]))\n",
        "    test_loader = torch.utils.data.DataLoader(test_data_, batch_size=64, shuffle=True)\n",
        "    \n",
        "    #定义网络与参数更新方法\n",
        "    model = Net()\n",
        "    optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
        "    \n",
        "    #训练网络\n",
        "    num_prints = epochs * len(train_loader) // 100 + 1\n",
        "    acc_history = torch.zeros(num_prints, dtype=to_float)\n",
        "    iter_history = torch.zeros(num_prints, dtype=to_long)\n",
        "    model = model.to(device=device)# move the model parameters to CPU/GPU\n",
        "    for epoch in range(epochs):\n",
        "        for t, (x, y) in enumerate(train_loader):\n",
        "            model.train()\n",
        "            # Move the data to the proper device (GPU or CPU)\n",
        "            x = x.to(device=device, dtype=to_float)\n",
        "            y = y.to(device=device, dtype=to_long).clamp(max=5)\n",
        "\n",
        "            # Forward pass: compute scores and loss\n",
        "            scores = model(x)\n",
        "            loss = F.cross_entropy(scores, y)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            #Backwards pass: compute the gradient\n",
        "            loss.backward()\n",
        "\n",
        "            #Update the parameters\n",
        "            optimizer.step()\n",
        "\n",
        "            tt = t + epoch * len(train_loader)\n",
        "\n",
        "            if tt % 100 == 0 or (epoch == epochs - 1 and t == len(train_loader) - 1):\n",
        "                print(\"Epoch: %d, Iteration: %d, loss = %.4f\" %(epoch, tt, loss.item()))\n",
        "                acc = check_accuracy_part34(valid_loader, model)\n",
        "                acc_history[tt // 100] = acc\n",
        "                iter_history[tt // 100] = tt\n",
        "                print()\n",
        "    total.append(acc_history[-1])\n",
        "    \n",
        "final_acc = sum(total) / len(total) * 100\n",
        "print(\"Final accuracy: %.2f\" %final_acc)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extract classes:  tensor([3, 4, 8, 5, 7, 1]) \n",
            "\n",
            "Epoch: 0, Iteration: 0, loss = 1.8019\n",
            "Got 1071 / 6750 correct (15.87)\n",
            "\n",
            "Epoch: 0, Iteration: 100, loss = 1.7600\n",
            "Got 1822 / 6750 correct (26.99)\n",
            "\n",
            "Epoch: 0, Iteration: 200, loss = 1.7417\n",
            "Got 2172 / 6750 correct (32.18)\n",
            "\n",
            "Epoch: 0, Iteration: 300, loss = 1.6832\n",
            "Got 2495 / 6750 correct (36.96)\n",
            "\n",
            "Epoch: 0, Iteration: 363, loss = 1.5070\n",
            "Got 2857 / 6750 correct (42.33)\n",
            "\n",
            "Final accuracy: 42.33\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wA9JKbUeKhqj",
        "outputId": "c7a0e979-dba9-4e4e-b407-c4c7114a40bd"
      },
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.net = nn.Sequential(\n",
        "            nn.Conv2d(3, 6, 5),\n",
        "            nn.BatchNorm2d(6),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2, 2),\n",
        "            \n",
        "            nn.Conv2d(6, 16, 5),\n",
        "            nn.BatchNorm2d(16),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2, 2),\n",
        "            \n",
        "            nn.Conv2d(16, 32, 3),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2, 2),\n",
        "            \n",
        "            nn.Flatten(),\n",
        "            nn.Linear(1*1*32, 16),\n",
        "            nn.ReLU(),\n",
        "            \n",
        "            nn.Linear(16, 6),\n",
        "        )\n",
        "        \n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "model = Net()\n",
        "print(model)\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Net(\n",
            "  (net): Sequential(\n",
            "    (0): Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1))\n",
            "    (1): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU()\n",
            "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (4): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
            "    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (6): ReLU()\n",
            "    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (8): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1))\n",
            "    (9): ReLU()\n",
            "    (10): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (11): Flatten(start_dim=1, end_dim=-1)\n",
            "    (12): Linear(in_features=32, out_features=16, bias=True)\n",
            "    (13): ReLU()\n",
            "    (14): Linear(in_features=16, out_features=6, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8U3dQsk3MQnD",
        "outputId": "fe36ff9b-95e1-4493-f930-294792927f5f"
      },
      "source": [
        "#定义网络与参数更新方法\n",
        "model = Net()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
        "\n",
        "epochs = 10\n",
        "num_prints = epochs * len(train_loader) // 100 + 1\n",
        "acc_history = torch.zeros(num_prints, dtype=to_float)\n",
        "iter_history = torch.zeros(num_prints, dtype=to_long)\n",
        "model = model.to(device=device)# move the model parameters to CPU/GPU\n",
        "for epoch in range(epochs):\n",
        "    for t, (x, y) in enumerate(train_loader):\n",
        "        model.train()\n",
        "        # Move the data to the proper device (GPU or CPU)\n",
        "        x = x.to(device=device, dtype=to_float)\n",
        "        y = y.to(device=device, dtype=to_long).clamp(max=5)\n",
        "        \n",
        "        # Forward pass: compute scores and loss\n",
        "        scores = model(x)\n",
        "        loss = F.cross_entropy(scores, y)\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        #Backwards pass: compute the gradient\n",
        "        loss.backward()\n",
        "        \n",
        "        #Update the parameters\n",
        "        optimizer.step()\n",
        "        \n",
        "        tt = t + epoch * len(train_loader)\n",
        "        \n",
        "        if tt % 100 == 0 or (epoch == epochs - 1 and t == len(train_loader) - 1):\n",
        "            print(\"Epoch: %d, Iteration: %d, loss = %.4f\" %(epoch, tt, loss.item()))\n",
        "            acc = check_accuracy_part34(train_loader, model)\n",
        "            acc_history[tt // 100] = acc\n",
        "            iter_history[tt // 100] = tt\n",
        "            print()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0, Iteration: 0, loss = 1.8135\n",
            "Got 3855 / 23250 correct (16.58)\n",
            "\n",
            "Epoch: 0, Iteration: 100, loss = 1.7642\n",
            "Got 5414 / 23250 correct (23.29)\n",
            "\n",
            "Epoch: 0, Iteration: 200, loss = 1.7131\n",
            "Got 7011 / 23250 correct (30.15)\n",
            "\n",
            "Epoch: 0, Iteration: 300, loss = 1.6113\n",
            "Got 7689 / 23250 correct (33.07)\n",
            "\n",
            "Epoch: 1, Iteration: 400, loss = 1.3856\n",
            "Got 9334 / 23250 correct (40.15)\n",
            "\n",
            "Epoch: 1, Iteration: 500, loss = 1.2405\n",
            "Got 10537 / 23250 correct (45.32)\n",
            "\n",
            "Epoch: 1, Iteration: 600, loss = 1.2700\n",
            "Got 10640 / 23250 correct (45.76)\n",
            "\n",
            "Epoch: 1, Iteration: 700, loss = 1.2182\n",
            "Got 10642 / 23250 correct (45.77)\n",
            "\n",
            "Epoch: 2, Iteration: 800, loss = 1.1614\n",
            "Got 11425 / 23250 correct (49.14)\n",
            "\n",
            "Epoch: 2, Iteration: 900, loss = 1.1742\n",
            "Got 11922 / 23250 correct (51.28)\n",
            "\n",
            "Epoch: 2, Iteration: 1000, loss = 1.3511\n",
            "Got 12282 / 23250 correct (52.83)\n",
            "\n",
            "Epoch: 3, Iteration: 1100, loss = 1.1026\n",
            "Got 12249 / 23250 correct (52.68)\n",
            "\n",
            "Epoch: 3, Iteration: 1200, loss = 1.0681\n",
            "Got 12749 / 23250 correct (54.83)\n",
            "\n",
            "Epoch: 3, Iteration: 1300, loss = 0.9605\n",
            "Got 12970 / 23250 correct (55.78)\n",
            "\n",
            "Epoch: 3, Iteration: 1400, loss = 1.0458\n",
            "Got 13289 / 23250 correct (57.16)\n",
            "\n",
            "Epoch: 4, Iteration: 1500, loss = 1.1489\n",
            "Got 13300 / 23250 correct (57.20)\n",
            "\n",
            "Epoch: 4, Iteration: 1600, loss = 0.9568\n",
            "Got 13512 / 23250 correct (58.12)\n",
            "\n",
            "Epoch: 4, Iteration: 1700, loss = 0.9838\n",
            "Got 13470 / 23250 correct (57.94)\n",
            "\n",
            "Epoch: 4, Iteration: 1800, loss = 1.0667\n",
            "Got 13568 / 23250 correct (58.36)\n",
            "\n",
            "Epoch: 5, Iteration: 1900, loss = 1.0514\n",
            "Got 13867 / 23250 correct (59.64)\n",
            "\n",
            "Epoch: 5, Iteration: 2000, loss = 1.2116\n",
            "Got 13285 / 23250 correct (57.14)\n",
            "\n",
            "Epoch: 5, Iteration: 2100, loss = 1.0250\n",
            "Got 14074 / 23250 correct (60.53)\n",
            "\n",
            "Epoch: 6, Iteration: 2200, loss = 0.7180\n",
            "Got 14015 / 23250 correct (60.28)\n",
            "\n",
            "Epoch: 6, Iteration: 2300, loss = 0.9371\n",
            "Got 14311 / 23250 correct (61.55)\n",
            "\n",
            "Epoch: 6, Iteration: 2400, loss = 0.9924\n",
            "Got 14232 / 23250 correct (61.21)\n",
            "\n",
            "Epoch: 6, Iteration: 2500, loss = 0.9220\n",
            "Got 14164 / 23250 correct (60.92)\n",
            "\n",
            "Epoch: 7, Iteration: 2600, loss = 1.0516\n",
            "Got 14372 / 23250 correct (61.82)\n",
            "\n",
            "Epoch: 7, Iteration: 2700, loss = 0.8799\n",
            "Got 14338 / 23250 correct (61.67)\n",
            "\n",
            "Epoch: 7, Iteration: 2800, loss = 0.9541\n",
            "Got 14462 / 23250 correct (62.20)\n",
            "\n",
            "Epoch: 7, Iteration: 2900, loss = 1.0979\n",
            "Got 14718 / 23250 correct (63.30)\n",
            "\n",
            "Epoch: 8, Iteration: 3000, loss = 0.9227\n",
            "Got 14662 / 23250 correct (63.06)\n",
            "\n",
            "Epoch: 8, Iteration: 3100, loss = 0.9287\n",
            "Got 14667 / 23250 correct (63.08)\n",
            "\n",
            "Epoch: 8, Iteration: 3200, loss = 0.7403\n",
            "Got 14838 / 23250 correct (63.82)\n",
            "\n",
            "Epoch: 9, Iteration: 3300, loss = 1.0584\n",
            "Got 14520 / 23250 correct (62.45)\n",
            "\n",
            "Epoch: 9, Iteration: 3400, loss = 0.8271\n",
            "Got 14988 / 23250 correct (64.46)\n",
            "\n",
            "Epoch: 9, Iteration: 3500, loss = 0.9750\n",
            "Got 14437 / 23250 correct (62.09)\n",
            "\n",
            "Epoch: 9, Iteration: 3600, loss = 1.0233\n",
            "Got 15095 / 23250 correct (64.92)\n",
            "\n",
            "Epoch: 9, Iteration: 3639, loss = 1.6158\n",
            "Got 13979 / 23250 correct (60.12)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oEVJDfPqE-7H",
        "outputId": "b535166b-b5c4-4f4b-e235-36293596d5c5"
      },
      "source": [
        "main_dir=os.getcwd()\n",
        "train_dir=main_dir+\"/extract_train\"\n",
        "test_dir=main_dir+\"/extract_test\"\n",
        "\n",
        "epochs=1\n",
        "total=[]\n",
        "\n",
        "for i in range(5):\n",
        "    # 建立存放数据集的文件夹\n",
        "    if os.path.exists(train_dir) and os.path.exists(test_dir):\n",
        "        shutil.rmtree(train_dir)\n",
        "        shutil.rmtree(test_dir)\n",
        "        os.mkdir(train_dir)\n",
        "        os.mkdir(test_dir)\n",
        "    else:\n",
        "        os.mkdir(train_dir)\n",
        "        os.mkdir(test_dir)\n",
        "\n",
        "    # 生成6个随机数，用于提取数据集中的6类\n",
        "    class_6=torch.randperm(10)[:6]\n",
        "    print(\"Extract classes: \", class_6, \"\\n\")\n",
        "\n",
        "    # 提取6类并保存至新的文件夹\n",
        "    for i in range(50000):\n",
        "        train_label=train_data.imgs[i][1]\n",
        "\n",
        "        if train_label in class_6:\n",
        "            train_label_dir=train_dir+\"/\"+str(train_label)\n",
        "            if os.path.exists(train_label_dir):\n",
        "                pass\n",
        "            else:\n",
        "                os.mkdir(train_label_dir)\n",
        "            image_path=train_data.imgs[i][0]\n",
        "            image=Image.open(image_path)\n",
        "            save_path=train_label_dir+\"/\"+str(i)+\".jpg\"\n",
        "            image.save(save_path)\n",
        "\n",
        "    for i in range(10000):\n",
        "        test_label=test_data.imgs[i][1]\n",
        "\n",
        "        if test_label in class_6:\n",
        "            test_label_dir=test_dir+\"/\"+str(test_label)\n",
        "            if os.path.exists(test_label_dir):\n",
        "                pass\n",
        "            else:\n",
        "                os.mkdir(test_label_dir)\n",
        "            image_path=test_data.imgs[i][0]\n",
        "            image=Image.open(image_path)\n",
        "            save_path=test_label_dir+\"/\"+str(i)+\".jpg\"\n",
        "            image.save(save_path)\n",
        "\n",
        "    # 定义预处理操作\n",
        "    Transforms = transforms.Compose([\n",
        "      transforms.Resize((224, 224)),\n",
        "      transforms.RandomHorizontalFlip(p=0.5),\n",
        "      transforms.ToTensor(),\n",
        "      transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))])\n",
        "\n",
        "    # 数据集预处理\n",
        "    train_data_=datasets.ImageFolder(train_dir, transform=transform)\n",
        "    test_data_=datasets.ImageFolder(test_dir, transform=transform)\n",
        "\n",
        "    # 数据集采样、打包\n",
        "    n_train=len(train_data_)  # 30000\n",
        "\n",
        "    split=23250\n",
        "    indices=list(range(n_train))\n",
        "    random.shuffle(indices)\n",
        "    test_loader=torch.utils.data.DataLoader(test_data_, batch_size=6000, shuffle=True)\n",
        "\n",
        "    # 定义网络与参更新方法\n",
        "    model=Net()\n",
        "    optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
        "\n",
        "    # 训练网络\n",
        "    num_prints=epochs*len(test_loader)//100+1\n",
        "    acc_history=torch.zeros(num_prints, dtype=to_float)\n",
        "    iter_history=torch.zeros(num_prints, dtype=to_long)\n",
        "    model=model.to(device=device)  # move the model parameters to CPU/GPU\n",
        "    for epoch in range(epochs):\n",
        "        for t, (x, y) in enumerate(test_loader):\n",
        "            model.eval()\n",
        "            # Move the data to the proper device (GPU or CPU)\n",
        "            x=x.to(device=device, dtype=to_float)\n",
        "            y=y.to(device=device, dtype=to_long).clamp(max=5)\n",
        "            tt=t+epoch*len(test_loader)\n",
        "\n",
        "            if tt%100==0 or (epoch==epochs-1 and t==len(test_loader)-1):\n",
        "                print(\"Epoch: %d, Iteration: %d, loss = %.4f\"%(epoch, tt, loss.item()))\n",
        "                acc=check_accuracy_part34(test_loader, model)\n",
        "                acc_history[tt//100]=acc\n",
        "                iter_history[tt//100]=tt\n",
        "                print()\n",
        "    total.append(acc_history[-1])\n",
        "\n",
        "final_acc=sum(total)/len(total)*100\n",
        "print(\"Final accuracy: %.2f\"%final_acc)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extract classes:  tensor([7, 2, 8, 0, 1, 9]) \n",
            "\n",
            "Epoch: 0, Iteration: 0, loss = 1.6158\n",
            "Got 1000 / 6000 correct (16.67)\n",
            "\n",
            "Extract classes:  tensor([7, 4, 3, 6, 1, 9]) \n",
            "\n",
            "Epoch: 0, Iteration: 0, loss = 1.6158\n",
            "Got 1000 / 6000 correct (16.67)\n",
            "\n",
            "Extract classes:  tensor([0, 9, 4, 2, 6, 3]) \n",
            "\n",
            "Epoch: 0, Iteration: 0, loss = 1.6158\n",
            "Got 1000 / 6000 correct (16.67)\n",
            "\n",
            "Extract classes:  tensor([1, 9, 0, 4, 6, 2]) \n",
            "\n",
            "Epoch: 0, Iteration: 0, loss = 1.6158\n",
            "Got 1000 / 6000 correct (16.67)\n",
            "\n",
            "Extract classes:  tensor([7, 6, 0, 4, 2, 9]) \n",
            "\n",
            "Epoch: 0, Iteration: 0, loss = 1.6158\n",
            "Got 992 / 6000 correct (16.53)\n",
            "\n",
            "Final accuracy: 16.64\n"
          ]
        }
      ]
    }
  ]
}